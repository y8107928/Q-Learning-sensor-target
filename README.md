# Q-Learning-sensor-target
这次，我们利用最基础的Q学习实现一个多智能体的分配任务。
利用单智能体的算法解决多智能体问题，是多智能体强化学习中的一种集中式处理的思路，需要注意的是，所有智能体要保证是信息共享的。

我们这次的例子，是传感器调度的一个例子。
为了方便理解，这里我换一下表述，假想你是一个篮球教练，现在你要布置战术，让每名防守球员迅速的找到对应的对方球员进行防守，要求一名防守球员对应一名对方进攻球员，并且，为了节省体力，每名防守球员都倾向于对位距离最近的对方球员。我们多加一些约束，就是每个防守球员只能看到一定范围内的进攻球员。
好，程序中的sensor传感器就是防守球员，而目标target就是进攻球员。
现在，你要完成一个在篮球战术中被称为人盯人的防守战术。

用一个环境类SensorEnv设定好所有传感器和目标的位置坐标和编号，并在其中写出计算其距离的函数。本程序中，设定5个传感器和5个目标。设定传感器只能检测到1000m范围内的目标，故通过get_state_start函数，得到所有传感器可检测到目标的一个组合，作为状态空间。

在主函数中，构建Q表，对应每个动作的Q值，并利用epsilon贪婪策略进行动作选择。学习的目标是，一个传感器对应跟踪一个目标，并且每个传感器都倾向于距离最短的目标，通过以上内容设计回报函数，并更新Q表。
